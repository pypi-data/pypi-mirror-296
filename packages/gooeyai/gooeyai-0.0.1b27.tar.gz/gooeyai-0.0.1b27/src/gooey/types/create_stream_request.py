# This file was auto-generated by Fern from our API Definition.

from ..core.pydantic_utilities import UniversalBaseModel
import pydantic
import typing
from .button_pressed import ButtonPressed
from .recipe_function import RecipeFunction
from .conversation_entry import ConversationEntry
from .large_language_models import LargeLanguageModels
from .embedding_models import EmbeddingModels
from .citation_styles import CitationStyles
from .asr_models import AsrModels
from .translation_models import TranslationModels
from .lipsync_models import LipsyncModels
from .llm_tools import LlmTools
from .response_format_type import ResponseFormatType
from .text_to_speech_providers import TextToSpeechProviders
from .open_ai_tts_voices import OpenAiTtsVoices
from .open_ai_tts_models import OpenAiTtsModels
from .sad_talker_settings import SadTalkerSettings
from ..core.pydantic_utilities import IS_PYDANTIC_V2


class CreateStreamRequest(UniversalBaseModel):
    integration_id: str = pydantic.Field()
    """
    Your Integration ID as shown in the Copilot Integrations tab
    """

    conversation_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    The gooey conversation ID.
    
    If not provided, a new conversation will be started and a new ID will be returned in the response. Use this to maintain the state of the conversation between requests.
    
    Note that you may not provide a custom ID here, and must only use the `conversation_id` returned in a previous response.
    """

    user_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    Your app's custom user ID.
    
    If not provided, a random user will be created and a new ID will be returned in the response. If a `conversation_id` is provided, this field is automatically set to the user's id associated with that conversation.
    """

    user_message_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    Your app's custom message ID for the user message.
    
    If not provided, a random ID will be generated and returned in the response. This is useful for tracking messages in the conversation.
    """

    button_pressed: typing.Optional[ButtonPressed] = pydantic.Field(default=None)
    """
    The button that was pressed by the user.
    """

    functions: typing.Optional[typing.List[RecipeFunction]] = None
    variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = pydantic.Field(default=None)
    """
    Variables to be used as Jinja prompt templates and in functions as arguments
    """

    input_prompt: typing.Optional[str] = None
    input_audio: typing.Optional[str] = None
    input_images: typing.Optional[typing.List[str]] = None
    input_documents: typing.Optional[typing.List[str]] = None
    doc_extract_url: typing.Optional[str] = pydantic.Field(default=None)
    """
    Select a workflow to extract text from documents and images.
    """

    messages: typing.Optional[typing.List[ConversationEntry]] = None
    bot_script: typing.Optional[str] = None
    selected_model: typing.Optional[LargeLanguageModels] = None
    document_model: typing.Optional[str] = pydantic.Field(default=None)
    """
    When your copilot users upload a photo or pdf, what kind of document are they mostly likely to upload? (via [Azure](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/use-sdk-rest-api?view=doc-intel-3.1.0&tabs=linux&pivots=programming-language-rest-api))
    """

    task_instructions: typing.Optional[str] = None
    query_instructions: typing.Optional[str] = None
    keyword_instructions: typing.Optional[str] = None
    documents: typing.Optional[typing.List[str]] = None
    max_references: typing.Optional[int] = None
    max_context_words: typing.Optional[int] = None
    scroll_jump: typing.Optional[int] = None
    embedding_model: typing.Optional[EmbeddingModels] = None
    dense_weight: typing.Optional[float] = pydantic.Field(default=None)
    """
    Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
    Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.
    """

    citation_style: typing.Optional[CitationStyles] = None
    use_url_shortener: typing.Optional[bool] = None
    asr_model: typing.Optional[AsrModels] = pydantic.Field(default=None)
    """
    Choose a model to transcribe incoming audio messages to text.
    """

    asr_language: typing.Optional[str] = pydantic.Field(default=None)
    """
    Choose a language to transcribe incoming audio messages to text.
    """

    translation_model: typing.Optional[TranslationModels] = None
    user_language: typing.Optional[str] = pydantic.Field(default=None)
    """
    Choose a language to translate incoming text & audio messages to English and responses back to your selected language. Useful for low-resource languages.
    """

    input_glossary_document: typing.Optional[str] = pydantic.Field(default=None)
    """
    Translation Glossary for User Langauge -> LLM Language (English)
    """

    output_glossary_document: typing.Optional[str] = pydantic.Field(default=None)
    """
    Translation Glossary for LLM Language (English) -> User Langauge
    """

    lipsync_model: typing.Optional[LipsyncModels] = None
    tools: typing.Optional[typing.List[LlmTools]] = pydantic.Field(default=None)
    """
    Give your copilot superpowers by giving it access to tools. Powered by [Function calling](https://platform.openai.com/docs/guides/function-calling).
    """

    avoid_repetition: typing.Optional[bool] = None
    num_outputs: typing.Optional[int] = None
    quality: typing.Optional[float] = None
    max_tokens: typing.Optional[int] = None
    sampling_temperature: typing.Optional[float] = None
    response_format_type: typing.Optional[ResponseFormatType] = None
    tts_provider: typing.Optional[TextToSpeechProviders] = None
    uberduck_voice_name: typing.Optional[str] = None
    uberduck_speaking_rate: typing.Optional[float] = None
    google_voice_name: typing.Optional[str] = None
    google_speaking_rate: typing.Optional[float] = None
    google_pitch: typing.Optional[float] = None
    bark_history_prompt: typing.Optional[str] = None
    elevenlabs_voice_name: typing.Optional[str] = pydantic.Field(default=None)
    """
    Use `elevenlabs_voice_id` instead
    """

    elevenlabs_api_key: typing.Optional[str] = None
    elevenlabs_voice_id: typing.Optional[str] = None
    elevenlabs_model: typing.Optional[str] = None
    elevenlabs_stability: typing.Optional[float] = None
    elevenlabs_similarity_boost: typing.Optional[float] = None
    elevenlabs_style: typing.Optional[float] = None
    elevenlabs_speaker_boost: typing.Optional[bool] = None
    azure_voice_name: typing.Optional[str] = None
    openai_voice_name: typing.Optional[OpenAiTtsVoices] = None
    openai_tts_model: typing.Optional[OpenAiTtsModels] = None
    input_face: typing.Optional[str] = None
    face_padding_top: typing.Optional[int] = None
    face_padding_bottom: typing.Optional[int] = None
    face_padding_left: typing.Optional[int] = None
    face_padding_right: typing.Optional[int] = None
    sadtalker_settings: typing.Optional[SadTalkerSettings] = None
    input_text: typing.Optional[str] = pydantic.Field(default=None)
    """
    Use `input_prompt` instead
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
