Metadata-Version: 2.1
Name: confidentialmind-app-helpers
Version: 0.1.3.post1
Summary: Helper functions for the ConfidentialMind stack, primarily for Streamlit apps
Author-email: confidentialmind <info@confidentialmind.com>
License: Apache-2.0
Project-URL: Homepage, https://www.confidentialmind.com/
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
License-File: NOTICE
Requires-Dist: pydantic >=2.8.2
Requires-Dist: websockets >=12.0
Requires-Dist: requests >=2.32.0
Requires-Dist: Pillow >=9.5.0
Requires-Dist: streamlit >=1.36.0
Requires-Dist: sseclient-py >=1.8.0
Requires-Dist: pyjwt >=2.8.0
Requires-Dist: python-dotenv >=1.0.1
Requires-Dist: confidentialmind-core >=0.1.2

# ConfidentialMind App Helpers

## Overview

The ConfidentialMind App package is a Python library designed to simplify the development of secure generative AI applications on the ConfidentialMind stack. It provides utility functions and components for building Streamlit-based front-end applications that interact with Large Language Models (LLMs) and other services within the ConfidentialMind ecosystem.

## Features

- Streamlit application initialization and configuration
- Tool selector for managing multiple tools within a single application
- Chat UI component for interacting with LLMs
- Streaming handler for real-time LLM responses
- User authentication and token management
- LLM API interaction helpers

## Installation

To install the package, add the following to your `requirements.txt` file:

```
pip install confidentialmind-app-helpers
```



## Usage

### Initializing a Streamlit App

```python
from confidentialmind_app_helpers.streamlit_utils.app import init_streamlit_app

def main():
    APP_NAME = "My ConfidentialMind App"
    init_streamlit_app(APP_NAME)

    # Your app code here

if __name__ == "__main__":
    main()
```

### Creating a Tool Selector

```python
from confidentialmind_app_helpers.streamlit_utils.app import tool_selector
from confidentialmind_core.config_manager import BaseToolConfig

def parse_tools_config(tools):
    # Your tool parsing logic here
    pass

tools = [BaseToolConfig(...), BaseToolConfig(...)]
tool_selector(tools, parse_tools_config, APP_NAME)
```

### Implementing a Chat UI

```python
from confidentialmind_app_helpers.streamlit_utils.components import chat_ui

LLM_CONFIG_ID = "your_llm_config_id"
chat_ui(LLM_CONFIG_ID, system_prompt="You are a helpful assistant.")
```

### Handling LLM API Requests

```python
from confidentialmind_app_helpers.llm_api_helpers import LLMAPIHandler, ChatMessage
from confidentialmind_app_helpers.streamlit_utils.components import StreamHandler

llm_api_handler = LLMAPIHandler(LLM_CONFIG_ID)
stream_handler = StreamHandler(st.empty())

messages = [ChatMessage(role="user", content="Hello, AI!")]
response = llm_api_handler.handle_query(messages, stream_handler.on_llm_new_token, temperature=0.7, stream=True)
```

## Components

- `app.py`: Contains functions for initializing Streamlit apps and managing tool selection.
- `components.py`: Provides UI components like the chat interface.
- `llm_api_helpers.py`: Handles interactions with LLM APIs.
- `streaming.py`: Manages streaming responses from LLMs.
- `user.py`: Handles user authentication and token management.

## Configuration

The package works in conjunction with the ConfidentialMind server package to manage configurations and connectors. Make sure to set up your `ConfigManager` and define necessary connectors as described in the main ConfidentialMind SDK documentation.

## Local Development

For local development:

1. Create a `.env` file in the root directory of your project.
2. Add the following lines to the `.env` file:
    ```
    CONFIDENTIAL_MIND_LOCAL_CONFIG=True
    ```
3. If your software has connectors and the respective service is also running locally, add the connector URLs to the `.env` file as well. For example, if the connector ID is `llm_connector` and the URL is `http://localhost:8083`, add the following line:
    ```
    llm_connector_URL=http://localhost:8083
    ```
4. If you want to **connect a locally running service to a service running on a remote ConfidentialMind stack**, add the URL and API key for the remote service to the `.env` file. For example, if the connector ID is `llm_connector` and the API key is `your-api-key`, add the following lines:
    ```
    llm_connector_URL=https://api.example.com/api/hrevxyjgdfwxkaguhpab/
    llm_connector_APIKEY=your-api-key
    ```
    **Note:** The URL and API key can be created and obtained from the ConfidentialMind portal: navigate to the service you want to connect to, click on the "API Keys" tab, and create a new API key. The URL and API key will be displayed there. You can also click the "Copy .env" button to copy the required environment variables to your clipboard. However, you must still replace the placeholder connector ID with the correct ID in the `.env` file.
4. The environment variables will be automatically loaded when you run the application.

Run your Streamlit application locally:
```
streamlit run main.py
```


## Note

This package is designed to work within the ConfidentialMind ecosystem. Make sure you have the necessary permissions and access to the ConfidentialMind stack before using this package.

For more detailed information on the ConfidentialMind SDK and its capabilities, please refer to the main SDK documentation.
