#
# Copyright 2023 DataRobot, Inc. and its affiliates.
#
# All rights reserved.
#
# DataRobot, Inc.
#
# This is proprietary source code of DataRobot, Inc. and its
# affiliates.
#
# Released under the terms of DataRobot Tool and Utility Agreement.
from __future__ import annotations

import io
import json
from json import dumps
import logging
import re
from typing import Any, cast, Dict, List, Optional, Tuple, Union

import aiohttp
import pandas as pd

from datarobotx.client.datasets import get_dataset, get_dataset_file
from datarobotx.client.prediction_servers import get_default_pred_server
from datarobotx.client.registered_models import create_registered_model_from_datarobot_model
from datarobotx.client.status import await_status, poll
from datarobotx.common.client import (
    raise_status_error,
    raise_value_error,
    read_resp_data,
    session,
    Session,
)
from datarobotx.common.config import context
from datarobotx.common.logging import tqdm
from datarobotx.common.types import TimeSeriesPredictParams
from datarobotx.common.utils import FilesSender, log_when_complete, PayloadType

logger = logging.getLogger("drx")


async def get_deployment(did: str) -> Dict[str, Any]:
    """Return the details for a deployment given a deployment id."""
    url = f"/deployments/{did}/"
    async with session.get(url) as resp:
        if resp.status != 200:
            await raise_value_error(resp)
        json = await resp.json()
        return cast(Dict[str, Any], json)


async def get_model_packages(model_package_id: str) -> Dict[str, Any]:
    """Return the model package (version) ostensibly from a deployment to understand its capabilities."""
    url = f"/modelPackages/{model_package_id}/"
    async with session.get(url) as resp:
        json_return = await resp.json()
        return cast(Dict[str, Any], json_return)


async def get_deployment_settings(did: str) -> Dict[str, Any]:
    """Return the settings from a deployment to understand its capabilities."""
    url = f"/deployments/{did}/settings/"
    async with session.get(url) as resp:
        json_return = await resp.json()
        return cast(Dict[str, Any], json_return)


async def deploy_learning_model(
    name: str, pid: str, model_id: str, registered_model_id: str = None
) -> str:
    """Create a deployment from a DR model."""
    description = f"Autogenerated from\nproject_id='{pid}'\nmodel_id='{model_id}'"
    server_id = context.pred_server_id or await get_default_pred_server()

    registered_model_version = await create_registered_model_from_datarobot_model(
        name=name,
        description=description,
        model_id=model_id,
        registered_model_id=registered_model_id,
    )
    url = "/deployments/fromModelPackage/"
    json = {
        "label": name,
        "description": description,
        "modelPackageId": registered_model_version,
    }
    if server_id:
        json.update(
            {
                "defaultPredictionServerId": server_id,
            }
        )
    async with session.post(url, json=json) as resp:
        if resp.status == 200:
            json = await resp.json()
            return json["id"]
        elif resp.status == 202:
            deploy_status_url = resp.headers["Location"]
        else:
            await raise_value_error(resp)
    logger.info("Awaiting deployment creation...")
    deploy_id = await poll(await_status, coro_args=[deploy_status_url])
    return cast(str, deploy_id)


async def post_dependency_build(custom_model_id: str, version_id: str) -> None:
    """Install additional packages to an environment version"""

    async def _await_status(url: str) -> Optional[bool]:
        """Poll status URL

        Returns None if response status == 200 (still in process)
        Needed because dependencyBuild reports status in non conventional way
        """
        resp = await session.get(url, allow_redirects=False)
        if resp.status == 200:
            json = await resp.json()
            if json["buildStatus"].upper() in ("ERROR", "ABORTED", "EXPIRED"):
                raise_status_error(url, json)
            if json["buildStatus"].upper() in ("SUCCESS"):
                return True
        else:
            await raise_value_error(resp)
        return None

    url = f"/customModels/{custom_model_id}/versions/{version_id}/dependencyBuild/"
    async with session.post(url) as resp:
        await resp.json()
    await poll(_await_status, coro_args=[url])
    return


async def create_custom_env(json: Dict[str, Any]) -> Optional[str]:  # type: ignore[return]
    """Create a custom execution environment.
    Returns the id of the new environment.
    """
    url = "/executionEnvironments/"
    async with session.post(url, json=json) as resp:
        if resp.status == 201:
            json = await resp.json()
            return cast(str, json["id"])
        await raise_value_error(resp)


async def get_custom_env(environment_id: str) -> Dict[str, Any]:
    """Return the details for a custom environment."""
    url = f"/executionEnvironments/{environment_id}/"
    async with session.get(url) as resp:
        if resp.status != 200:
            await raise_value_error(resp)
        json = await resp.json()
        return cast(Dict[str, Any], json)


async def create_custom_env_version(  # type: ignore[return]
    env_id: str, env_payload: Tuple[str, Union[bytes, io.BytesIO]]
) -> Optional[str]:
    """Create a custom environment version, uploading the environment archive.
    Returns the id of the auto-generated environment version.
    """
    file_name, data = env_payload
    url = f"/executionEnvironments/{env_id}/versions/"
    form_data = aiohttp.FormData()
    form_data.add_field("docker_context", data, filename=file_name)
    async with session.post(url, data=form_data) as resp:
        if resp.status == 202:
            url = resp.headers["Location"]
            return url.split("/")[-2]
        await raise_value_error(resp)


async def await_env_build(env_id: str, env_version_id: str) -> Optional[str]:
    """Wait for the build of the custom environment to complete."""

    async def _await_env_build(url: str) -> Optional[str]:  # type: ignore[return]
        resp = await session.get(url, allow_redirects=False)
        if resp.status == 200:
            json = await resp.json()
            status = json["buildStatus"]
            if status == "success":
                return cast(str, status)
            elif status == "failed":
                msg = f"Build of custom deployment environment '{env_id}' failed"
                raise ValueError(msg)
        else:
            await raise_value_error(resp)

    url = f"/executionEnvironments/{env_id}/versions/{env_version_id}/"
    coro_args = [url]
    status = await poll(_await_env_build, coro_args=coro_args)
    return cast(Optional[str], status)


async def create_custom_model(json: Dict[str, Any]) -> Optional[str]:  # type: ignore[return]
    """Create a custom model (does NOT upload the model package (version) or create a model
    version).
    Returns the id of the new custom model.
    """
    url = "/customModels/"
    async with session.post(url, json=json) as resp:
        if resp.status == 201:
            json = await resp.json()
            return cast(str, json["id"])
        await raise_value_error(resp)


async def create_custom_model_version(  # type: ignore[return]
    env_id: str, model_id: str, model_payload: List[PayloadType]
) -> Optional[str]:
    """Create a custom  model version, uploading custom model files.
    Returns the id of the new custom model version.
    """
    # files = files[:1]
    url = f"/customModels/{model_id}/versions/"
    form_data = aiohttp.FormData()
    form_data.add_field("baseEnvironmentId", env_id)
    sender = FilesSender(model_payload)
    for file_name, _ in model_payload:
        form_data.add_field("file", sender.reader(file_name), filename=file_name)
        form_data.add_field("filePath", file_name)
    async with session.post(url, data=form_data, timeout=None) as resp:
        if resp.status == 201:
            json = await resp.json()
            return cast(str, json["id"])
        await raise_value_error(resp)


async def patch_custom_model_version(  # type: ignore[return]
    base_environment_id: str,
    model_id: str,
    runtime_parameter_values: Optional[List[Dict[str, str]]] = None,
    is_major_update: bool = False,
) -> Optional[str]:
    """Patch a custom model version"""
    url = f"/customModels/{model_id}/versions/"
    body = {
        "isMajorUpdate": str(is_major_update).lower(),
        "baseEnvironmentId": base_environment_id,
    }
    if runtime_parameter_values is not None:
        body["runtimeParameterValues"] = dumps(runtime_parameter_values)
    async with session.patch(url, json=body) as resp:
        if resp.status == 201:
            json = await resp.json()
            return cast(str, json["id"])
        await raise_value_error(resp)


async def create_custom_model_package(  # type: ignore[return]
    model_id: str, model_version_id: str, env_id: str, env_version_id: str
) -> Optional[str]:
    """Create a model package (version) from a custom model.
    Returns a tuple (id, name)
    id of the new model package (version).
    """
    model_url = f"/customModels/{model_id}/"
    model_version_url = f"/customModels/{model_id}/versions/{model_version_id}/"
    env_url = f"/executionEnvironments/{env_id}/"
    env_version_url = f"/executionEnvironments/{env_id}/versions/{env_version_id}/"
    model_package_url = "/modelPackages/fromCustomModelVersion/"

    resp = await session.get(model_url, allow_redirects=False)
    json = await resp.json()
    model_name = json["name"]

    resp = await session.get(model_version_url, allow_redirects=False)
    json = await resp.json()
    model_version_label = json["label"]

    resp = await session.get(env_url, allow_redirects=False)
    json = await resp.json()
    env_name = json["name"]

    resp = await session.get(env_version_url, allow_redirects=False)
    json = await resp.json()
    env_version_label = json["label"]

    json = {
        "name": (model_name + f" ({model_version_label}) | {env_name} ({env_version_label})"),
        "customModelVersionId": model_version_id,
    }
    async with session.post(model_package_url, json=json) as resp:
        if resp.status == 201:
            json = await resp.json()
            return cast(str, json["id"])
        await raise_value_error(resp)


async def deploy_from_package(package_id: str, model_id: str) -> str:
    """Deploy a model package (version) built from a custom model."""
    model_url = f"/customModels/{model_id}/"
    deploy_url = "/deployments/fromModelPackage/"
    resp = await session.get(model_url, allow_redirects=False)
    json = await resp.json()
    model_name = json["name"]
    model_description = json["description"]
    server_id = context.pred_server_id or await get_default_pred_server()

    json = {
        "label": model_name,
        "description": model_description,
        "modelPackageId": package_id,
    }
    if server_id:
        json.update(
            {
                "defaultPredictionServerId": server_id,
            }
        )

    async with session.post(deploy_url, json=json) as resp:
        if resp.status == 200:
            json = await resp.json()
            return cast(str, json["id"])
        elif resp.status == 202:
            deploy_status_url = resp.headers["Location"]
        else:
            await raise_value_error(resp)
    deploy_id = await poll(await_status, coro_args=[deploy_status_url])
    return cast(str, deploy_id)


async def post_predictions(
    did: str,
    dr_key: str,
    pred_server_endpoint: str,
    payload: Tuple[str, io.BytesIO],
    ts_params: Optional[TimeSeriesPredictParams] = None,
    max_explanations: Union[int, str, None] = None,
    explanation_num_top_classes: Optional[int] = None,
) -> pd.DataFrame:
    """Make predictions on a deployment.

    Parameters
    ----------
    did: str
        Deployment id of the deployment
    max_explanations: int, None or 'all' (default=None)
        Number of explanations to return for each prediction.
        'all' is only valid for deployments with SHAP as the explanation
        method
    """
    logger.info("Uploading dataset to be scored...")
    params: Dict[str, Any] = {}
    if max_explanations is not None:
        params["maxExplanations"] = max_explanations
    if explanation_num_top_classes is not None:
        params["explanationNumTopClasses"] = explanation_num_top_classes
    if ts_params is not None:
        params.update(ts_params)
        if params.get("relaxKnownInAdvanceFeaturesCheck") is not None:
            params["relaxKnownInAdvanceFeaturesCheck"] = str(
                params["relaxKnownInAdvanceFeaturesCheck"]
            ).lower()

    url = f"{pred_server_endpoint}/deployments/{did}/predictions"
    pred_headers = {"Accept": "text/csv"}
    if dr_key:
        pred_headers["DataRobot-Key"] = dr_key

    file_name, _ = payload
    form_data = aiohttp.FormData()
    sender = FilesSender(payload)
    form_data.add_field(
        "file",
        log_when_complete(sender.reader(file_name), "Scoring..."),
        filename=file_name,
    )
    form_data.add_field("value", file_name)
    async with session.post(
        url,
        data=form_data,
        headers=pred_headers,
        params=params,
        timeout=None,
    ) as resp:
        if resp.status == 200:
            return pd.read_csv(io.StringIO(await resp.text()))
        elif resp.status == 400:
            # Explicitly raise an error because DataRobot doesn't show message in response headers
            message = await resp.text()
            error_message = (
                f"Received unexpected {resp.status} response code from DataRobot from "
                + f'"{resp.url}".'
                + re.sub("^message", " ", message).strip()
            )
            raise ValueError(error_message)
        else:
            await raise_value_error(resp)


async def post_predictions_unstructured(
    did: str, dr_key: str, pred_server_endpoint: str, data: Union[pd.DataFrame, Dict[str, Any]]
) -> Dict[str, Any]:
    """Make unstuctured predictions on a deployment."""
    url = f"{pred_server_endpoint}/deployments/{did}/predictionsUnstructured"
    json_data = json.dumps(data).encode("utf-8")
    pred_headers = {"DataRobot-Key": dr_key} if dr_key else None
    async with session.post(url, data=json_data, headers=pred_headers, timeout=None) as resp:
        if resp.status != 200:
            await raise_value_error(resp)
        return_data = await resp.text()
        return cast(Dict[str, Any], json.loads(return_data))


async def post_batch_predictions(
    did: str,
    payload: Tuple[str, io.BytesIO],
    ts_params: Optional[TimeSeriesPredictParams] = None,
    max_explanations: Optional[int] = None,
    explanation_num_top_classes: Optional[List[str]] = None,
) -> str:
    """Make batch predictions on a deployment."""
    logger.info("Uploading dataset to be scored...")
    if max_explanations is None:
        max_explanations = 0
    url = "/batchPredictions/"
    file_name, _ = payload
    sender = FilesSender(payload)
    jobSpec: Dict[str, Any] = {
        "deploymentId": did,
        "intakeSettings": {"type": "localFile"},
        "outputSettings": {"type": "localFile"},
        "maxExplanations": max_explanations,
    }
    if max_explanations > 0 and explanation_num_top_classes:
        jobSpec["explanationNumTopClasses"] = explanation_num_top_classes

    if ts_params:
        # Special configuration for batch jobs
        ts_params["type"] = "historical" if "predictionsStartDate" in ts_params else "forecast"
        ts_upload_params = {"timeseriesSettings": ts_params}
        jobSpec.update(ts_upload_params)

    async with session.post(url, json=jobSpec) as resp:
        if resp.status != 202:
            await raise_value_error(resp)
        else:
            full_resp = await resp.json()
            job_url = full_resp["links"]["self"]
            csv_up = full_resp["links"]["csvUpload"]

    await deployment_put(
        session=session,
        file_up=csv_up,
        data=log_when_complete(sender.reader(file_name), "Batch scoring..."),
        headers={"content-type": "text/csv"},
    )

    return cast(str, job_url)


async def deployment_put(
    session: Session, file_up: str, data: io.BytesIO, headers: dict
) -> aiohttp.ClientResponse:
    """Function to wrap PUT requests.
    This is being wrapped into a function in order to better
    faciliate unit tests which will consume the stream.

    Parameters
    ----------
    file_up : str
        URL to place PUT Request
    data : io.BytesIO
        Content of the request
    headers : dict
        headers to be included

    Returns
    -------
    aiohttp.ClientResponse
        returned response
    """
    async with session.put(path=file_up, data=data, headers=headers) as resp:
        if resp.status != 202:
            await raise_value_error(resp)


async def patch_shared_roles(did: str, json: Dict[str, Any]) -> int:
    """Share deployment with other users."""
    url = f"/deployments/{did}/sharedRoles/"
    async with session.patch(url, json=json) as resp:
        if resp.status != 204:
            await raise_value_error(resp)
    return resp.status


async def await_batch_job_completion(status_url: str) -> pd.DataFrame:
    """Poll whether batch job is done then get the data."""
    coro_args = [status_url]
    coro_kwargs: Dict[str, Any] = {}
    pid = await poll(await_status, coro_args=coro_args, coro_kwargs=coro_kwargs)
    result_df = await get_batch_job_results(pid)
    return result_df


async def get_batch_job_results(job_id: str) -> pd.DataFrame:
    logger.info("Downloading batch predictions...")
    url = f"/batchPredictions/{job_id}"

    async with session.get(url) as resp:
        j_data = await resp.json()
    download_link = j_data["links"]["download"]

    async with session.get(download_link, timeout=None) as resp:
        f = io.BytesIO()
        pbar = tqdm(
            bar_format="{n_fmt}{unit} [{elapsed}, {rate_fmt}]",
            unit="B",
            unit_scale=True,
            unit_divisor=1000,
        )
        await read_resp_data(resp, f, pbar)
        pbar.close()
        f.seek(0)
        return pd.read_csv(f)


async def post_training_data_exports(did: str) -> pd.DataFrame:
    """Return the training data used by the model in the provided deployment.
    Requires user to have access to both the project and deployment
    Note that this relies on an experimental API endpoint involving a feature flag.
    """

    async def return_if_finished(dataset_id: str) -> Optional[Dict[str, Any]]:  # type: ignore[return]
        json = await get_dataset(dataset_id)
        if json["processingState"] == "COMPLETED":
            return json

    url = f"/deployments/{did}/trainingDataExports/"
    async with session.post(url) as resp:
        if resp.status == 200:
            json = await resp.json()
            return json["id"]
        elif resp.status == 202:
            training_data_status_url = resp.headers["Location"]

    logger.info("Awaiting training dataset creation...")
    dataset_id = await poll(await_status, coro_args=[training_data_status_url])
    await poll(return_if_finished, coro_args=[dataset_id])
    dataset = await get_dataset_file(dataset_id)
    return dataset


async def search_deployments_for_match(pid: str) -> Dict[str, Any] | None:
    """Search for the first deployment affiliated with a project."""
    url = "/deployments?limit=100"
    async with session.get(url) as resp:
        while True:
            deployments = await resp.json()
            for deployment in deployments["data"]:
                if deployment["model"]["projectId"] == pid:
                    return cast(Dict[str, Any], deployment)
            if deployments["next"] is not None:
                resp = await session.get(deployments["next"])
            else:
                return None
