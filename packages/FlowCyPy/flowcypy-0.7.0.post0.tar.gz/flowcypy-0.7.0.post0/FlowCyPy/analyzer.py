
import pandas as pd
import matplotlib.pyplot as plt
from typing import List
from MPSPlots.styles import mps
from FlowCyPy import ureg
from FlowCyPy.utils import find_matching_indices
from FlowCyPy.dataset import DataSet
import warnings
import logging


class Analyzer:
    """
    A class to analyze pulse signals generated by a flow cytometer, extracting features
    such as pulse height, width, and area from the signal.

    Attributes
    ----------
    detectors : List[object]
        List of detector objects for analysis.

    Methods
    -------
    run_analysis(compute_peak_area=True, height_threshold=None):
        Detects and extracts features from signals.
    get_coincidence_dataset(coincidence_margin=0.1):
        Returns datasets where peak times from different detectors match within a given margin.
    find_peaks(detector, peak_area=True, height_threshold=None):
        Detects significant peaks and calculates their features.
    display_features():
        Displays detected features in tabular format.
    plot():
        Plots signals along with detected peaks.
    """

    def __init__(self, *detectors: object, algorithm: object) -> None:
        """
        Initializes the PeakAnalyzer with a list of detectors.

        Parameters
        ----------
        detectors : List[object]
            A list of detector objects that contain time and signal data.
        """
        self.algorithm = algorithm
        if len(detectors) != 2:
            raise ValueError("PeakAnalyzer currently supports exactly two detectors.")
        self.detectors = detectors
        self.datasets = []

    def run_analysis(self, compute_peak_area: bool = False) -> None:
        """
        Runs the peak analysis on all detectors and extracts features like heights, widths, and areas.

        Parameters
        ----------
        compute_peak_area : bool, optional
            Whether to compute the area under the peaks, by default True.
        """
        for detector in self.detectors:
            time, heights, widths, area = self.algorithm.detect_peaks(
                signal=detector.signal,
                time=detector.time,
                dt=detector.dt,
                compute_area=compute_peak_area,
            )
            dataset = DataSet(time=time, height=heights, width=widths, area=area)
            dataset.detector = detector
            self.datasets.append(dataset)

            logging.info(f"Peak analyzer has detected {dataset.height.size} events.")

    def get_coincidence_dataset(self, coincidence_margin: float = 0.1) -> List[DataSet]:
        """
        Finds peaks that coincide between detectors within a margin and returns the corresponding datasets.

        Parameters
        ----------
        coincidence_margin : float
            Time margin within which peaks are considered coincident, in seconds.

        Returns
        -------
        List[DataSet]
            A list of datasets with coincident peaks.
        """
        matching_index = find_matching_indices(
            array_0=self.datasets[0].time,
            array_1=self.datasets[1].time,
            margin=coincidence_margin
        )

        coincidence_datasets = []
        for idx, dataset in enumerate(self.datasets):
            c_dataset = DataSet(
                time=dataset.time[matching_index[:, idx]],
                height=dataset.height[matching_index[:, idx]],
                width=dataset.width[matching_index[:, idx]],
                area=dataset.area[matching_index[:, idx]] if dataset.area is not None else None
            )

            c_dataset.detector = dataset.detector

            coincidence_datasets.append(c_dataset)

        n_coincidences = len(coincidence_datasets[0].time)
        n_events_detector_0 = len(self.datasets[0].time)
        n_events_detector_1 = len(self.datasets[1].time)

        if n_coincidences == 0:
            warnings.warn("No coincidence measurements found.")

        logging.info(f"Peak analyzer has detected {n_coincidences} coincidence events.")

        if (n_coincidences > n_events_detector_0) or (n_coincidences > n_events_detector_1):
            warnings.warn(
                "The number of coincidences exceeds the number of events in one or both detectors. "
                "This may indicate that the time detection margin is too large."
            )

        return coincidence_datasets

    def display_features(self) -> None:
        """
        Displays extracted peak features for all datasets in a tabular format.
        """
        for i, dataset in enumerate(self.datasets):
            print(f"\nFeatures for Dataset {i + 1}:")
            dataset.print_properties()  # Reuse the print_properties method from DataSet


    def plot(self) -> None:
        """
        Plots the signal with detected peaks and widths at half-maximum, if available.
        """
        with plt.style.context(mps):
            fig, axes = plt.subplots(
                nrows=len(self.detectors),
                figsize=(10, 3 * len(self.detectors)),
                sharex=True
            )

            for ax, detector, dataset in zip(axes, self.detectors, self.datasets):
                ax.plot(detector.time.magnitude, detector.signal.magnitude, label='Signal')

                ax.vlines(dataset.time.magnitude, ymin=0, ymax=dataset.height.magnitude, color='r', label='Peaks')

                dataset._add_to_ax(ax, detector.time, detector.signal)

                handles, labels = ax.get_legend_handles_labels()
                by_label = dict(zip(labels, handles))
                ax.legend(by_label.values(), by_label.keys())

                ax.set_ylabel(f'{detector.name} signal [{detector.signal.units}]')

                ax.set_xlabel(f'Time [{detector.time.units}]')

            axes[0].set_xlabel('')
            plt.show()

    def to_dataframe(self) -> pd.DataFrame:
        """
        Extracts all the data from the datasets into a pandas DataFrame with multi-level columns.

        Returns
        -------
        pd.DataFrame
            A DataFrame containing time, height, width, and area (if available) for each detector.
            Uses multi-level columns with detector names as the top level and 'Time', 'Height',
            'Width', and 'Area' as the second level.
        """
        data_frames = []
        for dataset in self.datasets:
            # Create a dictionary for each dataset, using the detector's name as the key
            data_dict = {
                'Time': dataset.time.magnitude,
                'Height': dataset.height.magnitude,
                'Width': dataset.width.magnitude,
                'Area': dataset.area.magnitude if dataset.area is not None else None
            }

            # Convert the dictionary to a pandas DataFrame
            df = pd.DataFrame(data_dict)

            # Use the detector name as the top-level column
            df.columns = pd.MultiIndex.from_product([
                [dataset.detector.name + "detector"], df.columns]
            )

            data_frames.append(df)

        # Concatenate the DataFrames along the columns (axis=1) to align rows by index
        combined_df = pd.concat(data_frames, axis=1)

        return combined_df