import pandas as pd
from .parsing import ParsingInfo as ParsingInfo
from _typeshed import Incomplete as Incomplete

def parse_scenario(path: str, parsing_info: ParsingInfo | dict[str, ParsingInfo], trim_path: str = 'common', add_logs: bool = False, simplify_index: bool = False, time_scale: str = 's') -> pd.DataFrame:
    '''
    :param path: Path to execution scenario
    :param parsing_info: Parsing Information object to be used to parse the logs. In case of a multi solver scenario a dictionary is accepted with keys as solver names and values as their corresponding ParsingInfo
    :param trim_path: Trim path to the instance. Can be False (don\'t trim), "common" (trim the common path of the files), "name" (keep only the name of the files)
    :param add_logs: Add a `logs_path` column with the path to the output of the tasks. Can be False (don\'t add column), "trimmed" (add the trimmed path to the logs) or "full" (add the full path to the logs)
    :param simplify_index: Whether or not to simplify the row indexing when possible. If true, when the tasks are only executed with one seed, the seed will be added as a column but not as an index.
    :param time_scale: Scale to be used for the time values. Can be "s" (seconds) or "ms" (milliseconds)
    :returns: DataFrame with the parsed information
    '''
def average_over_seeds(df, column) -> None: ...
def num_solved(df) -> None: ...
def par_score(df, objective, par, max_value) -> None: ...

class LazyVerify:
    input: Incomplete
    formula_type: Incomplete
    formula: Incomplete
    def __init__(self, input, formula_type) -> None: ...
    def verify(self, model, cost) -> None: ...

def verify(df) -> None: ...
def virtual_best_solver(df) -> None: ...
def get_scores(df) -> None: ...
def get_scores_solvers(df) -> None: ...
